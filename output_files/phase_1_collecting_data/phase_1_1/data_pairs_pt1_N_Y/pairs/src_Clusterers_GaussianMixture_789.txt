    /**
     * Train the learner with a dataset.
     *
     * @param \Rubix\ML\Datasets\Dataset $dataset
     */

    public function train(Dataset $dataset) : void
    {
        SpecificationChain::with([
            new DatasetIsNotEmpty($dataset),
            new SamplesAreCompatibleWithEstimator($dataset, $this),
        ])->check();

        if ($this->logger) {
            $this->logger->info("$this initialized");
        }

        $this->initialize($dataset);

        $samples = $dataset->samples();
        $features = $dataset->features();

        $n = $dataset->numSamples();

        $minEpsilon = CPU::epsilon();
        $prevLoss = INF;

        $this->losses = [];

        for ($epoch = 1; $epoch <= $this->epochs; ++$epoch) {
            $loss = $maxVariance = 0.0;
            $memberships = [];

            foreach ($samples as $sample) {
                $jll = $this->jointLogLikelihood($sample);

                $total = logsumexp($jll);

                $loss -= $total;

                $dist = [];

                foreach ($jll as $cluster => $likelihood) {
                    $dist[$cluster] = exp($likelihood - $total);
                }

                $memberships[] = $dist;
            }

            if (is_nan($loss)) {
                if ($this->logger) {
                    $this->logger->info('Numerical instability detected');
                }

                break;
            }

            for ($cluster = 0; $cluster < $this->k; ++$cluster) {
                $affinities = array_column($memberships, $cluster);

                $total = array_sum($affinities);

                $means = $variances = [];

                foreach ($features as $column) {
                    $sigma = $ssd = 0.0;

                    foreach ($column as $i => $value) {
                        $sigma += $affinities[$i] * $value;
                    }

                    $mean = $sigma / $total;

                    foreach ($column as $i => $value) {
                        $ssd += $affinities[$i] * ($value - $mean) ** 2;
                    }

                    $variance = $ssd / $total;

                    $means[] = $mean;
                    $variances[] = $variance;
                }

                $maxVariance = max($maxVariance, ...$variances);

                $logPrior = log($total / $n);

                $this->means[$cluster] = $means;
                $this->variances[$cluster] = $variances;
                $this->logPriors[$cluster] = $logPrior;
            }

            $epsilon = max($this->smoothing * $maxVariance, $minEpsilon);

            foreach ($this->variances as &$variances) {
                foreach ($variances as &$variance) {
                    $variance += $epsilon;
                }
            }

            $loss /= $n;

            $this->losses[$epoch] = $loss;

            if ($this->logger) {
                $this->logger->info("Epoch $epoch - loss: $loss");
            }

            if ($loss <= 0.0) {
                break;
            }

            if (abs($loss - $prevLoss) < $this->minChange) {
                break;
            }

            $prevLoss = $loss;
        }

        if ($this->logger) {
            $this->logger->info('Training complete');
        }
    }
