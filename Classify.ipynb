{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from utility import classification\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'data/training/no_preprocessing.csv',\n",
    "    'data/training/freq_filt.csv',\n",
    "    'data/training/lowercase.csv',\n",
    "    'data/training/ngrams.csv',\n",
    "    'data/training/stem.csv',\n",
    "    'data/training/tf_ponderisanje.csv',\n",
    "]\n",
    "\n",
    "C = [0.03, 0.1, 1, 10, 30]\n",
    "C_SVC = [0.25, 1, 4]\n",
    "\n",
    "classifiers = {\n",
    "    'MNB': {name.split('/')[-1].split('.')[0]: [] for name in files},\n",
    "    'LogReg': {name.split('/')[-1].split('.')[0]: {c: [] for c in C} for name in files},\n",
    "    'SVM': {name.split('/')[-1].split('.')[0]: {c: [] for c in C_SVC} for name in files}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_Results = pd.DataFrame(columns=['dataset', 'classifier', 'hyperparameter', 'metric', 'value'])\n",
    "\n",
    "dataframes = {\n",
    "    name.split('/')[-1].split('.')[0]: pd.read_csv(name) for name in files\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with LogReg\n"
     ]
    }
   ],
   "source": [
    "for data in dataframes:\n",
    "    y = dataframes[data]['Score'].copy()\n",
    "    X = dataframes[data].drop(columns=['PairID', 'QueryID', 'Comment', 'Query', 'Score']).copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Logistic regression\n",
    "        for c in C:\n",
    "            clf = LogisticRegression(\n",
    "                penalty='l2', \n",
    "                C=c, \n",
    "                multi_class='multinomial', \n",
    "                solver='saga',\n",
    "                class_weight='balanced'\n",
    "            ).fit(X_train, y_train)\n",
    "\n",
    "            classifiers['LogReg'][data][c].append(clf)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            Classification_Results.loc[len(Classification_Results)] = [\n",
    "                data, 'LogReg', c, 'recall', recall_score(y_test, y_pred, average='macro')\n",
    "            ]\n",
    "            Classification_Results.loc[len(Classification_Results)] = [\n",
    "                data, 'LogReg', c, 'precision', precision_score(y_test, y_pred, average='macro')\n",
    "            ]\n",
    "            Classification_Results.loc[len(Classification_Results)] = [\n",
    "                data, 'LogReg', c, 'fscore', f1_score(y_test, y_pred, average='macro')\n",
    "            ]\n",
    "        print('Done with LogReg')\n",
    "        \n",
    "#         # MNB\n",
    "#         clf = MultinomialNB().fit(X_train, y_train)\n",
    "#         classifiers['MNB'][data].append(clf)\n",
    "#         y_pred = clf.predict(X_test)\n",
    "#         Classification_Results.loc[len(Classification_Results)] = [\n",
    "#             data, 'MNB', 0, 'recall', recall_score(y_test, y_pred, average='macro')\n",
    "#         ]\n",
    "#         Classification_Results.loc[len(Classification_Results)] = [\n",
    "#             data, 'MNB', 0, 'recall', precision_score(y_test, y_pred, average='macro')\n",
    "#         ]\n",
    "#         Classification_Results.loc[len(Classification_Results)] = [\n",
    "#             data, 'MNB', 0, 'recall', f1_score(y_test, y_pred, average='macro')\n",
    "#         ]\n",
    "        \n",
    "        # SVC\n",
    "        for c in C:\n",
    "            clf = SVC(\n",
    "                C=c,\n",
    "                kernel='linear',\n",
    "                class_weight='balanced'\n",
    "            ).fit(X_train, y_train)\n",
    "\n",
    "            classifiers['SVM'][data][c].append(clf)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            Classification_Results.loc[len(Classification_Results)] = [\n",
    "                data, 'SVM', c, 'recall', recall_score(y_test, y_pred, average='macro')\n",
    "            ]\n",
    "            Classification_Results.loc[len(Classification_Results)] = [\n",
    "                data, 'SVM', c, 'recall', precision_score(y_test, y_pred, average='macro')\n",
    "            ]\n",
    "            Classification_Results.loc[len(Classification_Results)] = [\n",
    "                data, 'SVM', c, 'recall', f1_score(y_test, y_pred, average='macro')\n",
    "            ]\n",
    "        print('Done with SVC')\n",
    "    \n",
    "    print('Done with {}'.format(data))\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataframes:\n",
    "    y = dataframes[data]['Score'].copy()\n",
    "    X = dataframes[data].drop(columns=['PairID', 'QueryID', 'Comment', 'Query', 'Score']).copy()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # SVC\n",
    "        for c in C_SVC:\n",
    "            clf = SVC(\n",
    "                C=c,\n",
    "                kernel='linear',\n",
    "                class_weight='balanced'\n",
    "            ).fit(X_train, y_train)\n",
    "\n",
    "            classifiers['SVM'][data][c].append(clf)\n",
    "\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            Classification_Results.loc[len(Classification_Results)] = [\n",
    "                data, 'SVM', c, 'recall', recall_score(y_test, y_pred, average='macro')\n",
    "            ]\n",
    "            Classification_Results.loc[len(Classification_Results)] = [\n",
    "                data, 'SVM', c, 'recall', precision_score(y_test, y_pred, average='macro')\n",
    "            ]\n",
    "            Classification_Results.loc[len(Classification_Results)] = [\n",
    "                data, 'SVM', c, 'recall', f1_score(y_test, y_pred, average='macro')\n",
    "            ]\n",
    "        print('Done with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no_preprocessing'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'data/training/no_preprocessing.csv'.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>QueryID</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Query</th>\n",
       "      <th>Score</th>\n",
       "      <th>WordCountComment</th>\n",
       "      <th>WordCountQuery</th>\n",
       "      <th>MutualUnique</th>\n",
       "      <th>MutualWithRepetition</th>\n",
       "      <th>BOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>BookStackApp_BookStack_ActivityService_740</td>\n",
       "      <td>0</td>\n",
       "      <td>Daj novu instancu aktivnosti za trenutnog kori...</td>\n",
       "      <td>red sa prioritetom</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BookStackApp_BookStack_ActivityService_740</td>\n",
       "      <td>1</td>\n",
       "      <td>Daj novu instancu aktivnosti za trenutnog kori...</td>\n",
       "      <td>pretvaranje string u datum</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>BookStackApp_BookStack_ActivityService_740</td>\n",
       "      <td>2</td>\n",
       "      <td>Daj novu instancu aktivnosti za trenutnog kori...</td>\n",
       "      <td>sortiranje string liste</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       PairID  QueryID  \\\n",
       "0  BookStackApp_BookStack_ActivityService_740        0   \n",
       "1  BookStackApp_BookStack_ActivityService_740        1   \n",
       "2  BookStackApp_BookStack_ActivityService_740        2   \n",
       "\n",
       "                                             Comment  \\\n",
       "0  Daj novu instancu aktivnosti za trenutnog kori...   \n",
       "1  Daj novu instancu aktivnosti za trenutnog kori...   \n",
       "2  Daj novu instancu aktivnosti za trenutnog kori...   \n",
       "\n",
       "                        Query  Score  WordCountComment  WordCountQuery  \\\n",
       "0          red sa prioritetom      0                 7               3   \n",
       "1  pretvaranje string u datum      0                 7               4   \n",
       "2     sortiranje string liste      0                 7               3   \n",
       "\n",
       "   MutualUnique  MutualWithRepetition  BOW  \n",
       "0             0                     0  0.0  \n",
       "1             0                     0  0.0  \n",
       "2             0                     0  0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/training/no_preprocessing.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X = df[['WordCountComment', 'WordCountQuery', 'MutualUnique', 'MutualWithRepetition', 'BOW']]\n",
    "y = df['Score']\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upoređivanje L1 i L2 regularizacije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boris_majic/anaconda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/boris_majic/anaconda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "l1 = LogisticRegression(penalty='l1', solver='saga', class_weight='balanced', max_iter=200).fit(X_train, y_train)\n",
    "y_pred_l1 = l1.predict(X_test)\n",
    "\n",
    "l2 = LogisticRegression(penalty='l2', solver='saga', class_weight='balanced', max_iter=200).fit(X_train, y_train)\n",
    "y_pred_l2 = l2.predict(X_test)\n",
    "\n",
    "l2_2 = LogisticRegression(penalty='l2', solver='lbfgs', class_weight='balanced', max_iter=200).fit(X_train, y_train)\n",
    "y_pred_v2 = l2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13830,  8293,  1092,  3914],\n",
       "       [   28,    34,     4,    25],\n",
       "       [    9,    19,     2,    11],\n",
       "       [    7,     9,     1,     6]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15012,  2175,  4532,  5410],\n",
       "       [   31,     9,    17,    34],\n",
       "       [    9,     7,    11,    14],\n",
       "       [    8,     4,     3,     8]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13830,  8293,  1092,  3914],\n",
       "       [   28,    34,     4,    25],\n",
       "       [    9,    19,     2,    11],\n",
       "       [    7,     9,     1,     6]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/boris_majic/anaconda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/boris_majic/anaconda/lib/python3.6/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "l1 = LogisticRegression(penalty='l1', solver='saga', class_weight='balanced', max_iter=500).fit(X_train, y_train)\n",
    "l2 = LogisticRegression(penalty='l2', solver='saga', class_weight='balanced', max_iter=500).fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataType</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>F1_micro</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>F1_weighted</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>auc_class_0</th>\n",
       "      <th>auc_class_1</th>\n",
       "      <th>auc_class_2</th>\n",
       "      <th>auc_class_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>L1</td>\n",
       "      <td>0.547464</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>0.991148</td>\n",
       "      <td>0.547464</td>\n",
       "      <td>0.342440</td>\n",
       "      <td>0.547464</td>\n",
       "      <td>0.547464</td>\n",
       "      <td>0.181339</td>\n",
       "      <td>0.704515</td>\n",
       "      <td>0.547464</td>\n",
       "      <td>0.669989</td>\n",
       "      <td>0.518418</td>\n",
       "      <td>0.634174</td>\n",
       "      <td>0.672911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>L2</td>\n",
       "      <td>0.563627</td>\n",
       "      <td>0.252080</td>\n",
       "      <td>0.991182</td>\n",
       "      <td>0.563627</td>\n",
       "      <td>0.343035</td>\n",
       "      <td>0.563627</td>\n",
       "      <td>0.563627</td>\n",
       "      <td>0.185888</td>\n",
       "      <td>0.717680</td>\n",
       "      <td>0.563627</td>\n",
       "      <td>0.670101</td>\n",
       "      <td>0.616508</td>\n",
       "      <td>0.615056</td>\n",
       "      <td>0.647121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DataType Model Name  precision_micro  precision_macro  precision_weighted  \\\n",
       "0     test         L1         0.547464         0.251412            0.991148   \n",
       "1     test         L2         0.563627         0.252080            0.991182   \n",
       "\n",
       "   recall_micro  recall_macro  recall_weighted  F1_micro  F1_macro  \\\n",
       "0      0.547464      0.342440         0.547464  0.547464  0.181339   \n",
       "1      0.563627      0.343035         0.563627  0.563627  0.185888   \n",
       "\n",
       "   F1_weighted  Accuracy  auc_class_0  auc_class_1  auc_class_2  auc_class_3  \n",
       "0     0.704515  0.547464     0.669989     0.518418     0.634174     0.672911  \n",
       "1     0.717680  0.563627     0.670101     0.616508     0.615056     0.647121  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_train_df = classification.model_report(X=X_test, y=y_test, models={'L1': l1, 'L2': l2}, data_type='test')\n",
    "report_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_occurancies = {k: sum(y == k) for k in y.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 135725, 1: 413, 2: 158, 3: 120}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_occurancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_null = sum(y > 0)\n",
    "non_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_weights(x):\n",
    "    if x > 0:\n",
    "        return 100/non_null\n",
    "    else:\n",
    "        return 100/score_occurancies[0]\n",
    "\n",
    "y_weigths_binary = y.apply(lambda x: binary_weights(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_weigths = y.apply(lambda x: 0.25/score_occurancies[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 recall - 0.34303509448298697\n",
      "l1 recall - 0.3424403948118258\n",
      "l2 precision - 0.33537629047132866\n",
      "l1 precision - 0.3518356495523185\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f'l2 recall - {recall_score(y_test, y_pred_l2, average=\"macro\", sample_weight=y_weigths_binary)}')\n",
    "print(f'l1 recall - {recall_score(y_test, y_pred_l1, average=\"macro\", sample_weight=y_weigths_binary)}')\n",
    "print(f'l2 precision - {precision_score(y_test, y_pred_l2, average=\"macro\", sample_weight=y_weigths_binary)}')\n",
    "print(f'l1 precision - {precision_score(y_test, y_pred_l1, average=\"macro\", sample_weight=y_weigths_binary)}')\n",
    "# print(recall_score(y_test, y_pred_l2, average='macro', sample_weight=y_weigths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_pred = l1.predict(X_test)\n",
    "l2_pred = l2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13402,  1209,  7810,  4708],\n",
       "       [   25,    11,    30,    25],\n",
       "       [    8,     1,    17,    15],\n",
       "       [    4,     2,     9,     8]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, l1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15002,  1854,  4807,  5466],\n",
       "       [   31,    13,    18,    29],\n",
       "       [    9,     3,    13,    16],\n",
       "       [    8,     1,     5,     9]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, l2_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pronalaženje optimalnog hiperparametra C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started an itteration\n",
      "Started an itteration\n",
      "Started an itteration\n",
      "Started an itteration\n",
      "Started an itteration\n",
      "Started an itteration\n",
      "Started an itteration\n",
      "Started an itteration\n",
      "Started an itteration\n",
      "Started an itteration\n"
     ]
    }
   ],
   "source": [
    "C = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "regularization_type = 'l2'\n",
    "\n",
    "LogRegRFP = pd.DataFrame(columns=['C', 'met''recall', 'precision', 'f-score'])\n",
    "\n",
    "\n",
    "if regularization_type == 'l2':\n",
    "    multiclass_approach = 'multinomial'\n",
    "    solver = 'saga'\n",
    "else:\n",
    "    multiclass_approach = 'ovr'\n",
    "    solver = 'liblinear'\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print('Started an itteration')\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for c in C:\n",
    "        clf = LogisticRegression(\n",
    "            penalty=regularization_type, \n",
    "            C=c, \n",
    "            multi_class=multiclass_approach, \n",
    "            solver=solver, \n",
    "            max_iter=192,\n",
    "            class_weight='balanced'\n",
    "            \n",
    "        ).fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        LogRegRFP.loc[len(LogRegRFP)] = [\n",
    "            c, \n",
    "            recall_score(y_test, y_pred, average='macro'),\n",
    "            precision_score(y_test, y_pred, average='macro'),\n",
    "            f1_score(y_test, y_pred, average='macro')\n",
    "        ]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.99490544, 0.99494191, 0.99494191, 0.99494191, 0.99494191]),\n",
       " array([0.99490544, 0.99494191, 0.99494191, 0.99494191, 0.99494191]),\n",
       " array([0.99490544, 0.99468534, 0.99494191, 0.99494191, 0.99494191]),\n",
       " array([0.99490544, 0.99494191, 0.99494191, 0.99494191, 0.99494191]),\n",
       " array([0.99490544, 0.99494191, 0.99494191, 0.99494191, 0.99494191])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136416,)\n",
      "(136416,)\n",
      "(136416,)\n",
      "(136416,)\n",
      "(136416,)\n",
      "(136416,)\n",
      "(136416,)\n",
      "(136416,)\n",
      "(136416,)\n",
      "(136416,)\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(sum(y[test_index] == 3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.407131</td>\n",
       "      <td>0.253166</td>\n",
       "      <td>0.183394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.347145</td>\n",
       "      <td>0.251361</td>\n",
       "      <td>0.183578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.390198</td>\n",
       "      <td>0.251184</td>\n",
       "      <td>0.183901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.400297</td>\n",
       "      <td>0.251564</td>\n",
       "      <td>0.179838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.370930</td>\n",
       "      <td>0.251217</td>\n",
       "      <td>0.153349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.384927</td>\n",
       "      <td>0.252253</td>\n",
       "      <td>0.179161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.282037</td>\n",
       "      <td>0.250201</td>\n",
       "      <td>0.181223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.310253</td>\n",
       "      <td>0.251023</td>\n",
       "      <td>0.176388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.298129</td>\n",
       "      <td>0.250632</td>\n",
       "      <td>0.151902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.294432</td>\n",
       "      <td>0.250621</td>\n",
       "      <td>0.187236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.300838</td>\n",
       "      <td>0.250344</td>\n",
       "      <td>0.175613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.225577</td>\n",
       "      <td>0.250018</td>\n",
       "      <td>0.173558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.418334</td>\n",
       "      <td>0.252618</td>\n",
       "      <td>0.178212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.357338</td>\n",
       "      <td>0.250834</td>\n",
       "      <td>0.185147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.372209</td>\n",
       "      <td>0.252033</td>\n",
       "      <td>0.171044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.354948</td>\n",
       "      <td>0.251774</td>\n",
       "      <td>0.179037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.357861</td>\n",
       "      <td>0.252269</td>\n",
       "      <td>0.191716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.327551</td>\n",
       "      <td>0.251430</td>\n",
       "      <td>0.180804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.372998</td>\n",
       "      <td>0.251139</td>\n",
       "      <td>0.171058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.380449</td>\n",
       "      <td>0.252099</td>\n",
       "      <td>0.182180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.282905</td>\n",
       "      <td>0.250205</td>\n",
       "      <td>0.117896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.275602</td>\n",
       "      <td>0.250838</td>\n",
       "      <td>0.211219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.313855</td>\n",
       "      <td>0.253930</td>\n",
       "      <td>0.163915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.427454</td>\n",
       "      <td>0.252886</td>\n",
       "      <td>0.174003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.374966</td>\n",
       "      <td>0.254109</td>\n",
       "      <td>0.190288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.413569</td>\n",
       "      <td>0.255437</td>\n",
       "      <td>0.195664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.385661</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.189220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.388758</td>\n",
       "      <td>0.252634</td>\n",
       "      <td>0.182640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.361114</td>\n",
       "      <td>0.250750</td>\n",
       "      <td>0.187726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.335194</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.182657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.385725</td>\n",
       "      <td>0.250346</td>\n",
       "      <td>0.182180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.438037</td>\n",
       "      <td>0.251218</td>\n",
       "      <td>0.183391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.390329</td>\n",
       "      <td>0.251658</td>\n",
       "      <td>0.182459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.291975</td>\n",
       "      <td>0.250566</td>\n",
       "      <td>0.179290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.433528</td>\n",
       "      <td>0.251621</td>\n",
       "      <td>0.184614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.399956</td>\n",
       "      <td>0.251305</td>\n",
       "      <td>0.176086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.389304</td>\n",
       "      <td>0.282073</td>\n",
       "      <td>0.196780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.375885</td>\n",
       "      <td>0.253079</td>\n",
       "      <td>0.183497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.371079</td>\n",
       "      <td>0.253458</td>\n",
       "      <td>0.191084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.380652</td>\n",
       "      <td>0.252040</td>\n",
       "      <td>0.198248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.305831</td>\n",
       "      <td>0.253891</td>\n",
       "      <td>0.185236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.344703</td>\n",
       "      <td>0.251603</td>\n",
       "      <td>0.168789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.211105</td>\n",
       "      <td>0.250233</td>\n",
       "      <td>0.183215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.232262</td>\n",
       "      <td>0.249982</td>\n",
       "      <td>0.180753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.226832</td>\n",
       "      <td>0.250777</td>\n",
       "      <td>0.183483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.202426</td>\n",
       "      <td>0.250537</td>\n",
       "      <td>0.181565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.212808</td>\n",
       "      <td>0.250215</td>\n",
       "      <td>0.171025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.272301</td>\n",
       "      <td>0.250495</td>\n",
       "      <td>0.170947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.390455</td>\n",
       "      <td>0.251657</td>\n",
       "      <td>0.181745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.315972</td>\n",
       "      <td>0.252937</td>\n",
       "      <td>0.187794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.311069</td>\n",
       "      <td>0.251062</td>\n",
       "      <td>0.178008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.292660</td>\n",
       "      <td>0.250647</td>\n",
       "      <td>0.177949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.270784</td>\n",
       "      <td>0.249982</td>\n",
       "      <td>0.180055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.345962</td>\n",
       "      <td>0.250836</td>\n",
       "      <td>0.155035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.251117</td>\n",
       "      <td>0.250633</td>\n",
       "      <td>0.165001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.297971</td>\n",
       "      <td>0.250632</td>\n",
       "      <td>0.173641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.303115</td>\n",
       "      <td>0.250026</td>\n",
       "      <td>0.168792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.306565</td>\n",
       "      <td>0.251406</td>\n",
       "      <td>0.183090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0.376621</td>\n",
       "      <td>0.254941</td>\n",
       "      <td>0.192573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.240730</td>\n",
       "      <td>0.250283</td>\n",
       "      <td>0.168345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C    recall  precision   f-score\n",
       "0     0.001  0.407131   0.253166  0.183394\n",
       "1     0.010  0.347145   0.251361  0.183578\n",
       "2     0.100  0.390198   0.251184  0.183901\n",
       "3     1.000  0.400297   0.251564  0.179838\n",
       "4    10.000  0.370930   0.251217  0.153349\n",
       "5   100.000  0.384927   0.252253  0.179161\n",
       "6     0.001  0.282037   0.250201  0.181223\n",
       "7     0.010  0.310253   0.251023  0.176388\n",
       "8     0.100  0.298129   0.250632  0.151902\n",
       "9     1.000  0.294432   0.250621  0.187236\n",
       "10   10.000  0.300838   0.250344  0.175613\n",
       "11  100.000  0.225577   0.250018  0.173558\n",
       "12    0.001  0.418334   0.252618  0.178212\n",
       "13    0.010  0.357338   0.250834  0.185147\n",
       "14    0.100  0.372209   0.252033  0.171044\n",
       "15    1.000  0.354948   0.251774  0.179037\n",
       "16   10.000  0.357861   0.252269  0.191716\n",
       "17  100.000  0.327551   0.251430  0.180804\n",
       "18    0.001  0.372998   0.251139  0.171058\n",
       "19    0.010  0.380449   0.252099  0.182180\n",
       "20    0.100  0.282905   0.250205  0.117896\n",
       "21    1.000  0.275602   0.250838  0.211219\n",
       "22   10.000  0.313855   0.253930  0.163915\n",
       "23  100.000  0.427454   0.252886  0.174003\n",
       "24    0.001  0.374966   0.254109  0.190288\n",
       "25    0.010  0.413569   0.255437  0.195664\n",
       "26    0.100  0.385661   0.253530  0.189220\n",
       "27    1.000  0.388758   0.252634  0.182640\n",
       "28   10.000  0.361114   0.250750  0.187726\n",
       "29  100.000  0.335194   0.251408  0.182657\n",
       "30    0.001  0.385725   0.250346  0.182180\n",
       "31    0.010  0.438037   0.251218  0.183391\n",
       "32    0.100  0.390329   0.251658  0.182459\n",
       "33    1.000  0.291975   0.250566  0.179290\n",
       "34   10.000  0.433528   0.251621  0.184614\n",
       "35  100.000  0.399956   0.251305  0.176086\n",
       "36    0.001  0.389304   0.282073  0.196780\n",
       "37    0.010  0.375885   0.253079  0.183497\n",
       "38    0.100  0.371079   0.253458  0.191084\n",
       "39    1.000  0.380652   0.252040  0.198248\n",
       "40   10.000  0.305831   0.253891  0.185236\n",
       "41  100.000  0.344703   0.251603  0.168789\n",
       "42    0.001  0.211105   0.250233  0.183215\n",
       "43    0.010  0.232262   0.249982  0.180753\n",
       "44    0.100  0.226832   0.250777  0.183483\n",
       "45    1.000  0.202426   0.250537  0.181565\n",
       "46   10.000  0.212808   0.250215  0.171025\n",
       "47  100.000  0.272301   0.250495  0.170947\n",
       "48    0.001  0.390455   0.251657  0.181745\n",
       "49    0.010  0.315972   0.252937  0.187794\n",
       "50    0.100  0.311069   0.251062  0.178008\n",
       "51    1.000  0.292660   0.250647  0.177949\n",
       "52   10.000  0.270784   0.249982  0.180055\n",
       "53  100.000  0.345962   0.250836  0.155035\n",
       "54    0.001  0.251117   0.250633  0.165001\n",
       "55    0.010  0.297971   0.250632  0.173641\n",
       "56    0.100  0.303115   0.250026  0.168792\n",
       "57    1.000  0.306565   0.251406  0.183090\n",
       "58   10.000  0.376621   0.254941  0.192573\n",
       "59  100.000  0.240730   0.250283  0.168345"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogRegRFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
